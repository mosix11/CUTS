global_seed: 11
training_seed: &training_seed 11
dataset_seed: &dataset_seed 11


strategy:
  finetuning_set: &finetuning_set 'Val'
  noise:

    finetuning:
      - set: 'Train'
        noise_rate: 1.0
        noise_type: 'symmetric'
        seed: 12
      - set: 'Train'
        noise_rate: 1.0
        noise_type: 'symmetric'
        seed: 10
      - set: 'Train'
        noise_rate: 1.0
        noise_type: 'symmetric'
        seed: 14

dataset:
  name: "food101"
  num_classes: &num_classes 101
  img_size: [224, 224]
  batch_size: 64
  val_from_test_size: 2500
  valset_ratio: 0.0
  num_workers: 12
  seed: *dataset_seed


model:
  type: 'dinov3'
  num_classes: *num_classes
  pt_weights: 'facebook/dinov3-vitb16-pretrain-lvd1689m'
  loss_fn:
    type: 'CE'
  metrics: ['ACC', 'F1']



trainer:
  finetuning:
    mix:
      max_iterations: 50000  # for batch size 128
      optimizer_cfg: 
        type: "adamw"
        lr: 1.0e-5
        betas: [0.9, 0.999]
      lr_schedule_cfg:
        type: 'cosann_warmup'
        update_on: 'gradient_step'
        warmup_steps: 300
        hold_steps: 20000
        T_max: 50000
        eta_min: 0
      early_stopping: False
      validation_freq: -1
      save_best_model: False
      checkpoint_freq: -1
      run_on_gpu: True
      use_amp: True
      log_comet: True
      comet_project_name: 'dino-realworld-TA'
      seed: *training_seed
    noise:
      max_iterations: 8000 # this is for batch size 64 now
      optimizer_cfg: 
        type: "adamw"
        lr: 1.0e-5
        betas: [0.9, 0.999]
      lr_schedule_cfg:
        type: 'cosann_warmup'
        update_on: 'gradient_step'
        warmup_steps: 300
        hold_steps: 4000
        T_max: 8000
        eta_min: 0
      early_stopping: False
      validation_freq: -1
      save_best_model: False
      checkpoint_freq: -1
      run_on_gpu: True
      use_amp: True
      log_comet: True
      comet_project_name: 'dino-realworld-TA'
      seed: *training_seed
