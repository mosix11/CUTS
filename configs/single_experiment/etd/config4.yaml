# Train on corrupted low loss samples
training_seed: &training_seed 11
dataset_seed: &dataset_seed 11


strategy:
  # finetuning_set: &finetuning_set 'LowLoss'
  # percentage: 0.4
  noise:
    set: 'Train'
    noise_rate: 0.1
    noise_type: 'symmetric'
    seed: 8

dataset:
  name: "cifar10"
  num_classes: &num_classes 10
  img_size: [32, 32]
  batch_size: 1024
  subsample_size: [-1, -1]
  class_subset: []
  remap_labels: False
  heldout_conf: null
  grayscale: False
  normalize_imgs: True
  flatten: False
  valset_ratio: 0.0
  num_workers: 8
  seed: *dataset_seed


model:
  standard:
    type: 'cnn5_etd'
    num_channels: 64
    num_classes: *num_classes
    dropout:
      p_fixed: 0.2
      p_mem: 0.1
      num_training_samples: 50000
      eval_mode: 'standard'
    loss_fn: 'CE'
    metrics: ['ACC', 'F1']
  drop:
    type: 'cnn5_etd'
    num_channels: 64
    num_classes: *num_classes
    dropout:
      p_fixed: 0.2
      p_mem: 0.1
      num_training_samples: 50000
      eval_mode: 'drop'
    loss_fn: 'CE'
    metrics: ['ACC', 'F1']

trainer:
  max_epochs: 200
  optimizer_cfg: 
    type: "adam"
    lr: 1.0e-4
    betas: [0.9, 0.999]
  lr_schedule_cfg: null
  early_stopping: False
  validation_freq: -1
  save_best_model: False
  checkpoint_freq: -1
  run_on_gpu: True
  use_amp: True
  log_comet: True
  comet_project_name: 'example-tied-dropout'
  seed: *training_seed

